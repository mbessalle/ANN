{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of glorious.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRpOhtA6BHf4",
        "colab_type": "code",
        "outputId": "fb741146-8209-4a77-9a64-e4e7a522615c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!pip install colorama mnist \n",
        "\n",
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import mnist\n",
        "import numpy as np\n",
        "import json \n",
        "\n",
        "\n",
        "np.random.seed(420)\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: mnist in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mnist) (1.16.3)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di1P_wjYA8dH",
        "colab_type": "text"
      },
      "source": [
        "# Data Pre-Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4_sONWhBO5m",
        "colab_type": "text"
      },
      "source": [
        "*  We are using the MNIST dataset in order to train and test our model.  \n",
        "*  MNIST is database of handwritten digits , has a training set of 60,000 examples, and a test set of 10,000 examples. \n",
        "*  The digits have been size-normalized and centered in a fixed-size image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkXTjQ9dBSh-",
        "colab_type": "code",
        "outputId": "2a26e806-8cad-45c7-926e-f9b901483d62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "train_img = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "\n",
        "print(train_img.shape,train_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoVE-UEDBagR",
        "colab_type": "text"
      },
      "source": [
        "**The input data** of the mnist dataset is one huge bitmap containing all 60000 images one after the other. The dataset needs to be sliced to get each image as a sepparate matrix so that we can feed it to the first layer of the NN. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6t7badVBc2x",
        "colab_type": "code",
        "outputId": "585738a2-9f31-41f2-f3e6-cf9d0f9f1e02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X = np.array(train_img).reshape(len(train_img), 28 * 28) \n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9x2p21zC5ty",
        "colab_type": "code",
        "outputId": "4d439685-07a9-4e54-d037-30bb4255f682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "first_image = np.array(X[0], dtype='float')\n",
        "plt.imshow(first_image.reshape(28, 28))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiF5Nq_RBmLm",
        "colab_type": "text"
      },
      "source": [
        "  **The output data** of the mnist dataset is a long array of single digits representing the correct digit that should be predicted by the model. However,  this data needs to be encoded in a matrix format. One-hot encoding takes care of that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80W2k-fFLzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(targets, nb_classes):\n",
        "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "    return res.reshape(list(targets.shape)+[nb_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3I7INCFFNn8",
        "colab_type": "text"
      },
      "source": [
        "The one_hot function provides a simple interface to convert class label integers into an array where each unique label is represented as a column in the new array.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Af5qy_TEvWo",
        "colab_type": "code",
        "outputId": "7a99504b-4eb3-40c6-c70f-3234b32dc3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(train_labels[0], '>',  one_hot(train_labels[0], 10))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 > [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9rVj733jb-t",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcG_zDBqGC4x",
        "colab_type": "code",
        "outputId": "8ffcb5fa-660a-40d5-817c-671b11d74868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y = one_hot(train_labels, 10)\n",
        "print(train_labels.shape, '>', Y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,) > (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HadK_446GhHx",
        "colab_type": "text"
      },
      "source": [
        "# Parameter selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrj8n6HWGs-i",
        "colab_type": "text"
      },
      "source": [
        "### Number of Nodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NacfndADGmtA",
        "colab_type": "code",
        "outputId": "84ac5d2b-b446-4fe7-d370-e0ac4d39ab22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s_x = X.shape[1]\n",
        "s_y = Y.shape[1]\n",
        "s_h = 250\n",
        "print('IN:', s_x, 'HIDDEN:', s_h, 'OUT:', s_y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IN: 784 HIDDEN: 250 OUT: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npbnfTueKbrH",
        "colab_type": "text"
      },
      "source": [
        "### Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wzNoOmxK4sy",
        "colab_type": "text"
      },
      "source": [
        "Weights  represent the strength of the connection between units.\n",
        "* If the weight from node 1 to node 2 has greater magnitude, it means that neuron 1 has greater influence over neuron 2. \n",
        "* A weight brings down the importance of the input value. \n",
        "* Weights near zero means changing this input will not change the output.\n",
        "* Negative weights mean increasing this input will decrease the output.\n",
        "* A weight decides how much influence the input will have on the output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfqBr9kELkaM",
        "colab_type": "text"
      },
      "source": [
        "To apply the chain rule successfully The shape of the weight matrices needs to match the shape of the input data. \n",
        "hem with random normally distributed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9SUSrRWLgLw",
        "colab_type": "code",
        "outputId": "3052506d-f6be-4571-b049-6e4cf8627c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s_weight1 = (s_x, s_h)\n",
        "s_weight2 = (s_h, s_y)\n",
        "print(s_weight1, s_weight2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 250) (250, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8llVuW3Rlid",
        "colab_type": "code",
        "outputId": "2f605c86-3e6d-4067-8121-a048f6a5a5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "limit_1 = np.sqrt(6 / (s_x + s_h))\n",
        "limit_2 = np.sqrt(6 / (s_h + s_y))\n",
        "\n",
        "print(-limit_1, limit_1)\n",
        "print(-limit_2, limit_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.07617550741785384 0.07617550741785384\n",
            "-0.15191090506255 0.15191090506255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87G8dsjibMXJ",
        "colab_type": "text"
      },
      "source": [
        "Something something limit "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1jVgX_JNYn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w1 = np.random.uniform(-limit_1, limit_1, size=s_weight1)\n",
        "w2 = np.random.uniform(-limit_2, limit_2, size=s_weight2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBSy5Mo8ONSR",
        "colab_type": "text"
      },
      "source": [
        "### Bias "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO12bplbOVua",
        "colab_type": "text"
      },
      "source": [
        "The bias is an extra input to neurons and it is always 1, and has it’s own connection weight. \n",
        "This makes sure that even when all the inputs are none (all 0’s) there’s gonna be an activation in the neuron or i think the reverse in this case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAuMpHbZObcf",
        "colab_type": "code",
        "outputId": "d91c4ad7-7de2-46d1-f57f-5947baeec05a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "s_bias1 = (1, s_h)\n",
        "s_bias2 = (1, s_y)\n",
        "print(s_bias1, s_bias2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 250) (1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arCJleXDPp7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b1 = np.zeros(shape=s_bias1)\n",
        "b2 = np.zeros(shape=s_bias2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ2t-TyORdrh",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5cb2G8CRvyt",
        "colab_type": "text"
      },
      "source": [
        "*  Gets initialised with the parameters\n",
        "*  Ensures safe data update\n",
        "*  gets updated in memory\n",
        "* can be saved to a file after training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj5gNM9TQvwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class model(object):\n",
        "\n",
        "    def __init__(self, W1, B1, W2, B2):\n",
        "        self.__w1 = W1\n",
        "        self.__b1 = B1\n",
        "        self.__w2 = W2\n",
        "        self.__b2 = B2\n",
        "\n",
        "    def update(self, d_w1, d_b1, d_w2, d_b2, learning_rate = 1.2):\n",
        "        self.__w1 = self.__w1 - learning_rate * d_w1\n",
        "        self.__w2 = self.__w2 - learning_rate * d_w2\n",
        "        self.__b1 = self.__b1 - learning_rate * d_b1\n",
        "        self.__b2 = self.__b2 - learning_rate * d_b2\n",
        "\n",
        "    def w1(self): return self.__w1\n",
        "    def w2(self): return self.__w2\n",
        "    def b1(self): return self.__b1\n",
        "    def b2(self): return self.__b2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmE-MSnVR_Q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_model = model(w1, b1, w2, b2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2zRgYDTOw7",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0J7Zna8Ti_q",
        "colab_type": "text"
      },
      "source": [
        "## Activation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgD3kxvmWZHN",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://cdn-images-1.medium.com/max/1000/1*XxxiA0jJvPrHEJHD4z893g.png)\n",
        "*  **ReLU** is the most used activation function in the world right now. \n",
        "*  Using a sigmoid or tanh will cause almost all neurons to fire in an analog way \n",
        "    * That means almost all activations will be processed to describe the output of a network.\n",
        "    * In other words the activation is dense. This is costly. \n",
        "    * We would ideally want a few neurons in the network to not activate and thereby making the activations sparse and efficient.\n",
        "* However, there's a problem -->  For activations in that region of ReLu, gradient will be 0 because of which the weights will not get adjusted during descent --> Dying ReLu\n",
        "* We solve this by limiting the weights and using clipping\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGCfMarQTuTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ReLU(x, deriv=False):\n",
        "    if deriv:\n",
        "        return (x > 0).astype(float)\n",
        "    return x * (x > 0).astype(float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCgmsStATqxJ",
        "colab_type": "text"
      },
      "source": [
        "## Summation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1PnAoxHYckm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* **Softmax**  is a function that takes as input a vector of X real numbers, and normalizes it into a probability distribution consisting of X probabilities\n",
        "* Basically we apply the standard exponential function to each element of the input vector and normalize these values by dividing by the sum of all these exponentials\n",
        "* Normalization ensures that the sum of the probabilities omponents of the output vector is 1\n",
        "\n",
        "| Sigmoid  | Softmax   |\n",
        "|---|---|\n",
        "|  The probabilities sum will be 1|  The probabilities sum need not be 1.  |\n",
        "|  Used in the different layers of neural networks. | Used as activation function while building neural network  |\n",
        "|  The high value will have the higher probability than other values. | Used as activation function while building neural network  |\n",
        "\n",
        "\n",
        "*   Basically, the sigmoid works best for binary classification, and softmax works best for multi-classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vtb5QUBZT3AD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    max_x = np.amax(x, 1, keepdims=True)\n",
        "\n",
        "    normalized = x - max_x\n",
        "    exponents = np.exp(normalized)\n",
        "    return exponents/exponents.sum(1, keepdims=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGneamJqUK46",
        "colab_type": "text"
      },
      "source": [
        "## Cost\n",
        "*  When we develop a model for probabilistic classification, we aim to map the model's inputs to probabilistic predictions.\n",
        "* The model is trained by incrementally adjusting the model's parameters so that our predictions get closer and closer to ground-truth probabilities\n",
        "* Cross-entropy is commonly used to quantify the difference between two probability distributions. \n",
        "* Usually the \"true\" distribution (the one that your machine learning algorithm is trying to match) is expressed in terms of a one-hot distribution.\n",
        "  * we encoded the labels using one-hot in the data pre-processing part \n",
        "* Our model is based around the assumption that classes are mutually exclusive (eg. a digit cant' be a 6 and a 9 at the same time)\n",
        "* Cross entropy \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyXgl2w9TTb_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy(a2, y):\n",
        "    N = a2.shape[0]\n",
        "    clipped = np.clip(a2, 1e-10, 1)\n",
        "    \n",
        "    return -1/N*np.sum(y * np.log(clipped))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKh7UjdZVL3g",
        "colab_type": "text"
      },
      "source": [
        "# Feed-Forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJJKpjpARKpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, w1, b1, w2, b2):\n",
        "    z1 = np.dot(X, w1) + b1\n",
        "    a1 = ReLU(z1)\n",
        "    \n",
        "    z2 = np.dot(a1, w2) + b2\n",
        "    a2 = softmax(z2)\n",
        "    \n",
        "    return a1, a2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XODB2t7OVVb1",
        "colab_type": "text"
      },
      "source": [
        "# Back-Propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX4z_VuyRLVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward_propagation(X, Y, W1, W2, A1, A2, b1, b2, clipping=False):\n",
        "    dZ2 = A2 - Y\n",
        "    db2 = dZ2\n",
        "    dW2 = A1.T @ dZ2\n",
        "    dA1 = dZ2 @ W2.T\n",
        "    dZ1 = ReLU(A1, True) * dA1\n",
        "    db1 = dZ1\n",
        "    dW1 = X.T @ dZ1\n",
        "\n",
        "    if clipping:\n",
        "        dW1 = np.clip(dW1, -50, 50)\n",
        "        dW2 = np.clip(dW2, -100, 100)\n",
        "\n",
        "    return dW1, db1, dW2, db2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RXUnXvzxhOc",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UqXG6KF3cGa",
        "colab_type": "text"
      },
      "source": [
        "Before training, we have defined a method that uses MatPlotLib to graph the gradients, cost and weights as the model is trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkVro3_lxgIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterations = 50\n",
        "graph_refresh_rate = 1\n",
        "decimals = 4        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq5oxLgyB21g",
        "colab_type": "code",
        "outputId": "a3237ef9-e92e-43e8-ea52-20d7ecbeee6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "for i in range(iterations):\n",
        "  w1 = _model.w1()\n",
        "  w2 = _model.w2()\n",
        "  b1 = _model.b1()\n",
        "  b2 = _model.b2()\n",
        "\n",
        "  a1, a2 = forward_propagation(X, w1, b1, w2, b2)\n",
        "  cost = cross_entropy(a2, Y)\n",
        "  \n",
        "  dw1, db1, dw2, db2 = backward_propagation(X, Y, w1, w2, a1, a2, b1, b2)\n",
        "  _model.update(dw1, db1, dw2, db2)\n",
        "      \n",
        "  if i % graph_refresh_rate == 0 and i > 0:\n",
        "    cost = round(cost, decimals)\n",
        "    w1_n = np.round_(np.linalg.norm(w1), decimals)\n",
        "    w2_n = np.round_(np.linalg.norm(w2), decimals)\n",
        "    \n",
        "    print(\"i: {} / Cost: {} / W1: {} /  W2: {}\".format(i ,cost, w1_n, w2_n))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i: 1 / Cost: 20.3706 / W1: 43557904.5258 /  W2: 29254024.4\n",
            "i: 2 / Cost: 20.4266 / W1: 395208380237347.1 /  W2: 2242898224366225.5\n",
            "i: 3 / Cost: 19.3889 / W1: 3.938981244192908e+20 /  W2: 8.025083481605251e+19\n",
            "i: 4 / Cost: 0.1173 / W1: 9.561240840595252e+24 /  W2: 4.795807895028518e+26\n",
            "i: 5 / Cost: 0.0971 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 6 / Cost: 0.084 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 7 / Cost: 0.0742 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 8 / Cost: 0.0666 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 9 / Cost: 0.0605 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 10 / Cost: 0.0555 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 11 / Cost: 0.0513 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 12 / Cost: 0.0477 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 13 / Cost: 0.0446 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 14 / Cost: 0.0419 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 15 / Cost: 0.0395 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 16 / Cost: 0.0374 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 17 / Cost: 0.0355 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 18 / Cost: 0.0338 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 19 / Cost: 0.0323 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 20 / Cost: 0.0309 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 21 / Cost: 0.0296 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 22 / Cost: 0.0284 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 23 / Cost: 0.0274 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 24 / Cost: 0.0264 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 25 / Cost: 0.0254 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 26 / Cost: 0.0246 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 27 / Cost: 0.0237 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 28 / Cost: 0.023 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 29 / Cost: 0.0223 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 30 / Cost: 0.0216 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 31 / Cost: 0.021 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 32 / Cost: 0.0204 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 33 / Cost: 0.0198 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 34 / Cost: 0.0193 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 35 / Cost: 0.0188 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 36 / Cost: 0.0183 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 37 / Cost: 0.0179 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 38 / Cost: 0.0175 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 39 / Cost: 0.0171 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 40 / Cost: 0.0167 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 41 / Cost: 0.0163 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 42 / Cost: 0.0159 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 43 / Cost: 0.0156 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 44 / Cost: 0.0153 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 45 / Cost: 0.015 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 46 / Cost: 0.0147 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 47 / Cost: 0.0144 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 48 / Cost: 0.0141 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n",
            "i: 49 / Cost: 0.0138 / W1: 1.9155713637450244e+28 /  W2: 1.3046670897941235e+27\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
